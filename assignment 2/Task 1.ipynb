{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pmdarima as pm\n",
    "from pmdarima import pipeline, arima, model_selection\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_P = os.path.join(os.getcwd(), 'Elspotprices2nd.csv')\n",
    "df_prices = pd.read_csv(file_P)\n",
    "df_prices['HourUTC'] = pd.to_datetime(df_prices['HourUTC'])\n",
    "\n",
    "file_P = os.path.join(os.getcwd(), 'ProdConData.csv')\n",
    "df_data = pd.read_csv(file_P)\n",
    "df_data['HourUTC'] = pd.to_datetime(df_data['HourUTC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices[\"SpotPriceDKK\"].max()\n",
    "\n",
    "#mean spot price is 643.112\n",
    "#lowest is -447.459\n",
    "#highest is 6982.64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must define the training dataset, which runs from 1/1/19 until 31/8/24, and the testing dataset, which runs from 1/9/24 until 30/9/24. For that we will visualize the data and then split it into the two groups.\n",
    "\n",
    "**The provided data doesn't end on 30/09/2024, but on 31/12/202**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define relevant timestamps to filter only for the time periods mentioned in the task for training and testing\n",
    "#from start to end of testing data there are 720 data points\n",
    "\n",
    "#Filtering time period for training and testing data\n",
    "t_start = pd.Timestamp(dt.datetime(2019, 1, 1, 0, 0, 0))\n",
    "t_end = pd.Timestamp(dt.datetime(2024, 9, 30, 23, 0, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data filtering -- data remains as dataframe with HourUTC and SpotPriceDKK; drop indices after narrowing data down to specified dates\n",
    "\n",
    "reduced_df = df_prices.loc[(df_prices['HourUTC']>=t_start) & (df_prices['HourUTC']<=t_end)]\n",
    "reduced_df = reduced_df.reset_index(drop=True)\n",
    "\n",
    "#Data split \n",
    "train, test = model_selection.train_test_split(reduced_df[\"SpotPriceDKK\"], test_size=720)\n",
    "\n",
    "#n's are relevant for x \n",
    "n_train = len(train)\n",
    "n_test = len(test)\n",
    "n_data = len(reduced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data visualization\n",
    "plt.figure(figsize=(10, 4), dpi=100)\n",
    "plt.plot(np.arange(1,n_train+1), train)\n",
    "plt.plot(np.arange(n_train+1,n_data+1), test)\n",
    "plt.legend([\"Training set\", \"Testing set\"])\n",
    "plt.grid(alpha=0.25)\n",
    "plt.xticks(np.arange(0, n_data+1, 365*24), rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, day-ahead predictions will be done with a seasonal ARIMA model. 30 predictions are needed of 24 values each. The correct values for them are known--contained in the test dataset--, so the model will be updated after each forecast.\n",
    "\n",
    "A persistence model is included in the graph to use as benchmark for the model. Each new set of 24 values will be assumed to be equal to the previous 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with the appropriate m and k; m = 24 for daily seasonality and k = 4---k value is how smooth curve fitted is, and max should be m//2, so 12\n",
    "pipe = pipeline.Pipeline([\n",
    "    (\"fourier\", pm.preprocessing.FourierFeaturizer(m=24, k = 6)),\n",
    "    (\"arima\", arima.AutoARIMA(stepwise=False, trace = False, error_action=\"ignore\",\n",
    "                              seasonal=False, maxiter=10, \n",
    "                              suppress_warnings=True))])\n",
    "\n",
    "pipe.fit(train)\n",
    "\n",
    "# Create a list for the forecasts\n",
    "rolling_forecast = []\n",
    "N = int(len(test)/24)\n",
    "\n",
    "for i in range(N):\n",
    "    forecast = pipe.predict(n_periods=24)\n",
    "    pipe.update(test[i*24:(i+1)*24])\n",
    "    rolling_forecast.extend(forecast)\n",
    "\n",
    "# Plot forecasts\n",
    "plt.figure(figsize=(10, 4), dpi=100)\n",
    "plt.plot(np.arange(1,n_train+1), train)\n",
    "plt.plot(np.arange(n_train+1,n_data+1), test)\n",
    "plt.plot(np.arange(n_train+1,n_data+1), rolling_forecast)\n",
    "plt.title(\"24-hour ahead predictions\")\n",
    "plt.legend([\"Training set\", \"Actual values\", \"Forecasts\"])\n",
    "plt.grid(alpha=0.25)\n",
    "plt.xlim(n_data - 6*7*24, n_data)\n",
    "plt.ylim(top=4000)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the ARIMA with the persistance model we report the RMSE value of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting of benchmark,i.e daily persistence model\n",
    "\n",
    "data_spotprices = reduced_df[\"SpotPriceDKK\"].values\n",
    "\n",
    "#Empty list for 24 hour predictions\n",
    "Persistence24 = []\n",
    "\n",
    "for i in range(N):\n",
    "    Persistence24.extend(data_spotprices[len(train)+ 24 * (i - 1) : len(train) + i * 24])\n",
    "\n",
    "# Plot the forecasts\n",
    "plt.figure(figsize=(10, 4), dpi=100)\n",
    "plt.plot(np.arange(1,n_train+1), train)\n",
    "plt.plot(np.arange(n_train+1,n_data+1), test)\n",
    "plt.plot(np.arange(n_train+1,n_data+1), rolling_forecast)\n",
    "plt.plot(np.arange(n_train+1,n_data+1), Persistence24)\n",
    "plt.title(\"24-hour ahead predictions\")\n",
    "plt.legend([\"Training set\", \"Actual values\", \"Forecasts\", \"Daily persistence\"])\n",
    "plt.grid(alpha=0.25)\n",
    "plt.xlim(n_data - 6*7*24, n_data)\n",
    "plt.ylim(top=4000)\n",
    "plt.xlabel(\"Time [hours]\")\n",
    "plt.ylabel(\"Spot price [DKK/MWh]\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#RMSE for ARIMA and persistence.\n",
    "RMSE_P24 = root_mean_squared_error(Persistence24, test)\n",
    "RMSE_F = root_mean_squared_error(rolling_forecast, test)\n",
    "\n",
    "print(\"RMSE for daily persistence:\", round(RMSE_P24))\n",
    "print(\"RMSE for forecasts:\", round(RMSE_F))\n",
    "print(f\"The length of the rolling forecast and the persistence are {len(rolling_forecast)} and {len(Persistence24)}, respectively\")\n",
    "\n",
    "#with original data and k = 6, RMSE are 365 persistence and 309 forecats; 309 is the lowest RMSE for the forecast model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2\n",
    "\n",
    "We now add any exogenous variables to the model, creating an ARIMAX one. After testing different variable combinations, we opted for only two variables that had a positive correlation with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering the exogenous data to the same time period that we have for training and testing the price data.\n",
    "reduced_df_data = df_data.loc[(df_data['HourUTC']>=t_start) & (df_data['HourUTC']<=t_end)]\n",
    "reduced_df_data = reduced_df_data.reset_index(drop=True)\n",
    "reduced_df_data = reduced_df_data.fillna(0) #with this I'm replacing all NaN values with 0\n",
    "\n",
    "#Merging price and exogenous data\n",
    "reduced_df_merged = pd.merge(reduced_df, reduced_df_data, on='HourUTC')\n",
    "\n",
    "#Correlation analysis to observe effects on SpotPriceDKK\n",
    "corr = reduced_df_merged.drop(columns=['HourUTC']).corr(method='pearson')\n",
    "corr = corr.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an ARIMAX model; we already have train/test for price data\n",
    "#we need X_train and X_test, which will contain the exogenous data\n",
    "\n",
    "#spot price data split\n",
    "train, test = model_selection.train_test_split(reduced_df[\"SpotPriceDKK\"], test_size=720)\n",
    "\n",
    "#n's are relevant for x \n",
    "n_train = len(train)\n",
    "n_test = len(test)\n",
    "n_data = len(reduced_df)\n",
    "\n",
    "#choice 5 predictors and splitting the sets\n",
    "X_train, X_test = model_selection.train_test_split(reduced_df_merged[['CentralPowerMWh', 'CommercialPowerMWh']], test_size=720)\n",
    "\n",
    "#building the matrix for the ARIMAX model with the predictors\n",
    "X_train_ar = np.column_stack([np.arange(1, n_train+1), X_train])\n",
    "\n",
    "pipe = pipeline.Pipeline([\n",
    "    (\"fourier\", pm.preprocessing.FourierFeaturizer(m=24, k = 6)),\n",
    "    (\"arima\", arima.AutoARIMA(stepwise=False, trace=1, error_action=\"ignore\",\n",
    "                              seasonal=False, maxiter=10, \n",
    "                              suppress_warnings=True))])\n",
    "\n",
    "pipe.fit(train, X = X_train_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_forecast_multiple = []\n",
    "N = int(len(test)/24)\n",
    "\n",
    "for i in range(N):\n",
    "\n",
    "    X_f = np.column_stack([np.arange(1, 24+1), \n",
    "                           X_test[i*24:(i+1)*24]])\n",
    "\n",
    "    forecast = pipe.predict(n_periods=24, X = X_f)\n",
    "    \n",
    "    rolling_forecast_multiple.extend(forecast)\n",
    "\n",
    "    pipe.update(test[i*24:(i+1)*24], X = X_f)\n",
    "\n",
    "# Make any non-negative values equal to zero\n",
    "rolling_forecast_multiple = [0 if x < 0 else x for x in rolling_forecast_multiple]\n",
    "\n",
    "# Plot the forecasts\n",
    "plt.figure(figsize=(10, 4), dpi=100)\n",
    "plt.plot(np.arange(1,len(train)+1), train, color = \"black\")\n",
    "plt.plot(np.arange(n_train + 1, n_data + 1), rolling_forecast_multiple, color = \"blue\")\n",
    "plt.plot(np.arange(n_train+1,n_data+1), Persistence24, color = \"green\")\n",
    "plt.plot(np.arange(n_train + 1, n_data + 1), test, color = \"red\")\n",
    "plt.legend([\"Training set\", \"Forecasted values\", \"Persistence\", \"Actual values\"], loc = \"upper left\")\n",
    "plt.grid(alpha=0.25)\n",
    "plt.xlim(n_data - 6*7*24, n_data)\n",
    "plt.ylim(top=4000)\n",
    "plt.xlabel(\"Time [hours]\")\n",
    "plt.ylabel(\"Spot price [DKK/MWh]\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the error metrics\n",
    "RMSE_P24 = root_mean_squared_error(Persistence24, test)\n",
    "RMSE_F2 = root_mean_squared_error(rolling_forecast_multiple, test)\n",
    "\n",
    "print(f\"RMSE for daily persistence: {RMSE_P24:.2f}\")\n",
    "print(f\"RMSE for the new forecasts: {RMSE_F2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevant results of the correlation analysis:\n",
    "    \n",
    "- CentralPowerMWh (0.20)\n",
    "- OffshoreWindLt100MW_MWh (-0.26)\n",
    "- OnshoreWindLt50kW_MWh(-0.20)\n",
    "- OnshoreWindGe50kW_MWh (-0.31)\n",
    "- HydroPowerMWh (-0.24)\n",
    "- PowerToHeatMWh (-0.16)\n",
    "- CommercialPowerMWh (0.11)\n",
    "\n",
    "Tested combinations of exogenous variables:\n",
    "\n",
    "- Choice 1: OnshoreWindGe50kW_MWh (-0.31), OffshoreWindLt100MW_MWh (-0.26), HydroPowerMWh (-0.24)\n",
    "- Choice 2: OnshoreWindGe50kW_MWh (-0.31), OffshoreWindLt100MW_MWh (-0.26) \n",
    "- Choice 3: OnshoreWindGe50kW_MWh (-0.31), HydroPowerMWh (-0.24)\n",
    "- Choice 4: OnshoreWindGe50kW_MWh\n",
    "- Choice 5: CentralPowerMWh (0.20), CommercialPowerMWh (0.11)\n",
    "- Choice 6: CentralPowerMWh (0.20)\n",
    "\n",
    "RMSE for choice 1: 314.79 at k=12\n",
    "\n",
    "RMSE for choice 2: 313.83 at k=12, 312 at k=6, 317 at k=4\n",
    "\n",
    "RMSE for choice 3: 315.59 at k=6\n",
    "\n",
    "RMSE for choice 4: RMSE is *291.40 at k = 6*, 307.90 at k = 4, 309 at k = 8, 304 at k=7\n",
    "\n",
    "RMSE for choice 5: 309 at k = 6\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnergyAnalyticsF25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
