{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pmdarima as pm\n",
    "from pmdarima import pipeline, arima, model_selection\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_P = os.path.join(os.getcwd(), 'Elspotprices2nd.csv')\n",
    "df_prices = pd.read_csv(file_P)\n",
    "df_prices['HourUTC'] = pd.to_datetime(df_prices['HourUTC'])\n",
    "\n",
    "file_P = os.path.join(os.getcwd(), 'ProdConData.csv')\n",
    "df_data = pd.read_csv(file_P)\n",
    "df_data['HourUTC'] = pd.to_datetime(df_data['HourUTC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices[\"SpotPriceDKK\"].max()\n",
    "\n",
    "#mean spot price is 643.112\n",
    "#lowest is -447.459\n",
    "#highest is 6982.64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we must define the training dataset, which runs from 1/1/19 until 31/8/24, and the testing dataset, which runs from 1/9/24 until 30/9/24. For that we will visualize the data and then split it into the two groups.\n",
    "\n",
    "**The provided data doesn't end on 30/09/2024, but on 31/12/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define relevant timestamps to filter only for the time periods mentioned in the task for training and testing\n",
    "\n",
    "t_start = pd.Timestamp(dt.datetime(2019, 1, 1, 0, 0, 0))\n",
    "t_end = pd.Timestamp(dt.datetime(2024, 9, 30, 23, 0, 0))\n",
    "\n",
    "#from start to end of testing data there are 720 data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data filtering -- data remains as dataframe with HourUTC and SpotPriceDKK; drop indices after narrowing data down to specified dates\n",
    "\n",
    "reduced_df = df_prices.loc[(df_prices['HourUTC']>=t_start) & (df_prices['HourUTC']<=t_end)]\n",
    "reduced_df = reduced_df.reset_index(drop=True)\n",
    "\n",
    "#Data split \n",
    "train, test = model_selection.train_test_split(reduced_df[\"SpotPriceDKK\"], test_size=720)\n",
    "\n",
    "#Data split __ do the same as for regular data with train_test_split function; test should be 720 long\n",
    "\n",
    "#n's are relevant for x \n",
    "n_train = len(train)\n",
    "n_test = len(test)\n",
    "n_data = len(reduced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data visualization\n",
    "plt.figure(figsize=(10, 4), dpi=100)\n",
    "plt.plot(np.arange(1,n_train+1), train)\n",
    "plt.plot(np.arange(n_train+1,n_data+1), test)\n",
    "plt.legend([\"Training set\", \"Testing set\"])\n",
    "plt.grid(alpha=0.25)\n",
    "plt.xticks(np.arange(0, n_data+1, 365*24), rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, day-ahead predictions will be done with an ARIMA model (seasonal or not?). 30 predictions are needed of 24 values each. The correct values for them are known--contained in the test dataset--, so the model will be updated after each forecast.\n",
    "A persistence model is included in the graph to use as benchmark for the model. Each new set of 24 values will be assumed to be equal to the previous 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model characteristics: daily seasonality, training data set reduced to previous year (august 2023-2024))\n",
    "\n",
    "#t_start_reduced_train_fulldf = pd.Timestamp(dt.datetime(2022, 1, 1, 0, 0, 0))\n",
    "#t_end_reduced_train_fulldf = pd.Timestamp(dt.datetime(2024, 8, 31, 23, 0, 0))\n",
    "\n",
    "#reduced_train_fulldf = train_fulldf.loc[(df_prices['HourUTC']>=t_start_reduced_train_fulldf) & (df_prices['HourUTC']<=t_end_reduced_train_fulldf)]\n",
    "\n",
    "#reduced_train_spotprices = reduced_train_fulldf[\"SpotPriceDKK\"].values\n",
    "#train_spotprices = train_fulldf[\"SpotPriceDKK\"].values\n",
    "#test_spotprices = test_fulldf[\"SpotPriceDKK\"].values\n",
    "\n",
    "#n_train_reduced = len(reduced_train_fulldf)\n",
    "#n_data_reduced = n_train_reduced + n_test\n",
    "\n",
    "#ACF and PACF plots to detect seasonality \n",
    "\n",
    "# Plot ACF/PACF plots ==> shows strong correlations thorughout; the seasonality is strong on a daily basis\n",
    "'''\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8, 6))\n",
    "sm.graphics.tsa.plot_acf(reduced_train_spotprices, title = \"ACF\", lags=25, ax=ax[0])\n",
    "sm.graphics.tsa.plot_pacf(reduced_train_spotprices, title = \"PACF\", lags=25, ax=ax[1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "# Create a pipeline with the appropriate m and k; m = 24 for daily seasonality and k = 4---k value is how smooth curve fitted is, and max should be m//2, so 12\n",
    "pipe = pipeline.Pipeline([\n",
    "    (\"fourier\", pm.preprocessing.FourierFeaturizer(m=24, k = 6)),\n",
    "    (\"arima\", arima.AutoARIMA(stepwise=False, trace = False, error_action=\"ignore\",\n",
    "                              seasonal=False, maxiter=10, \n",
    "                              suppress_warnings=True))])\n",
    "\n",
    "pipe.fit(train)\n",
    "\n",
    "\n",
    "# Create a list for the forecasts\n",
    "rolling_forecast = []\n",
    "N = int(len(test)/24)\n",
    "\n",
    "for i in range(N):\n",
    "    forecast = pipe.predict(n_periods=24)\n",
    "    pipe.update(test[i*24:(i+1)*24])\n",
    "    rolling_forecast.extend(forecast)\n",
    "\n",
    "# Plot forecasts\n",
    "plt.figure(figsize=(10, 4), dpi=100)\n",
    "plt.plot(np.arange(1,n_train+1), train)\n",
    "plt.plot(np.arange(n_train+1,n_data+1), test)\n",
    "plt.plot(np.arange(n_train+1,n_data+1), rolling_forecast)\n",
    "plt.title(\"24-hour ahead predictions\")\n",
    "plt.legend([\"Training set\", \"Actual values\", \"Forecasts\"])\n",
    "plt.grid(alpha=0.25)\n",
    "plt.xlim(n_data - 6*7*24, n_data)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the ARIMA with the persistance model we report the RMSE value of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting of benchmark,i.e daily persistence model\n",
    "\n",
    "data_spotprices = reduced_df[\"SpotPriceDKK\"].values\n",
    "\n",
    "#Empty list for 24 hour predictions\n",
    "Persistence24 = []\n",
    "\n",
    "for i in range(N):\n",
    "    Persistence24.extend(data_spotprices[len(train)+ 24 * (i - 1) : len(train) + i * 24])\n",
    "\n",
    "# Plot the forecasts\n",
    "plt.figure(figsize=(10, 4), dpi=100)\n",
    "plt.plot(np.arange(1,n_train+1), train)\n",
    "plt.plot(np.arange(n_train+1,n_data+1), test)\n",
    "plt.plot(np.arange(n_train+1,n_data+1), rolling_forecast)\n",
    "plt.plot(np.arange(n_train+1,n_data+1), Persistence24)\n",
    "plt.title(\"24-hour ahead predictions\")\n",
    "plt.legend([\"Training set\", \"Actual values\", \"Forecasts\", \"Daily persistence\"])\n",
    "plt.grid(alpha=0.25)\n",
    "plt.xlim(n_data - 6*7*24, n_data)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#RMSE for ARIMA and persistence.\n",
    "RMSE_P24 = root_mean_squared_error(Persistence24, test)\n",
    "RMSE_F = root_mean_squared_error(rolling_forecast, test)\n",
    "\n",
    "print(\"RMSE for daily persistence: \", round(RMSE_P24))\n",
    "print(\"RMSE for forecasts: \", round(RMSE_F))\n",
    "\n",
    "#with original data and k = 6, RMSE are 365 persistence and 309 forecats; 309 is the lowest RMSE for the forecast model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2\n",
    "\n",
    "Add any exogenous variables you want (maximum 3) and repeat the process (choose/optimize\n",
    "your model and evaluate it for the day-ahead prediction).\n",
    "\n",
    "What exogenous variables helped you improve the prediction and how did you choose the specific ones?\n",
    "\n",
    "Report the RMSE value and compare your results with those from task 1.1 and briefly discuss them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge exogeneous data with og spot price data about Hour UTC column & do refiltering for stated months\n",
    "\n",
    "df_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EA25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
